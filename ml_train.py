import os
import pandas
import numpy
import pefile
import csv

import pickle
import pandas as pd 


import joblib

from sklearn.feature_selection import SelectFromModel

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import sklearn.ensemble as ek

from sklearn.metrics import confusion_matrix
from sklearn import svm

import sklearn.metrics as metrics
from sklearn.model_selection import train_test_split


# Dropping unnecessary str values as classification model will accept float and int only

def decisiontree_classifier_model(dataset_file=None):
	if dataset_file:
		dataset = pd.read_csv(dataset_file, sep='|')

		X = dataset.drop(['Name','md5','legitimate'],axis=1).values 

		# Target variable
		y = dataset['legitimate'].values

		extratrees = ek.ExtraTreesClassifier().fit(X,y)
		model = SelectFromModel(extratrees, prefit=True)
		X_new = model.transform(X)
		nbfeatures = X_new.shape[1]

		#splitting the data, 70% for training and 30% for testing
		X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)

		features = []
		index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]

		# Feature Selection
		for f in range(nbfeatures):
			features.append(dataset.columns[2+f])

    	# Training model	
		DTclassifier = DecisionTreeClassifier(max_depth=10)
		DTclassifier.fit(X_train,y_train)

		# Score
		score = round(DTclassifier.score(X_test,y_test)*100, 2)



		# Saving model and score to a csv file
		model_name = 'DecisionTreeclassifier.pkl'
		dataset_name = dataset_file.split('/')[1]
		with open('score.csv', mode='a', newline='') as file:
			writer = csv.writer(file)
			writer.writerow([model_name, dataset_name, f'{score} %'])

		# Saving Model
		joblib.dump(DTclassifier,f'models/{model_name}')
		open('models/features.pkl', 'wb').write(pickle.dumps(features))

		return None
	else:
		raise FileNotFoundError

def randomforest_classifier_model(dataset_file=None):
	if dataset_file:

		dataset = pd.read_csv(dataset_file, sep='|')
		legitimate_data = dataset[0:41323].drop(["legitimate"], axis=1)
		malware_data = dataset[41323::].drop(["legitimate"], axis=1)

		X = dataset.drop(['Name','md5','legitimate'],axis=1).values 

		# Target variable
		y = dataset['legitimate'].values

		extratrees = ek.ExtraTreesClassifier().fit(X,y)
		model = SelectFromModel(extratrees, prefit=True)
		X_new = model.transform(X)
		nbfeatures = X_new.shape[1]

		#splitting the data, 70% for training and 30% for testing
		X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)

		features = []
		index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]

		# Feature Selection
		for f in range(nbfeatures):
			features.append(dataset.columns[2+f])

		# Training model
		RFclassifier = RandomForestClassifier(n_estimators=50)
		RFclassifier.fit(X_train,y_train)

		# Score
		score = round(RFclassifier.score(X_test,y_test)*100, 2)


		# Saving 
		model_name = 'RandomForestclassifier.pkl'
		dataset_name = dataset_file.split('/')[1]
		with open('score.csv', mode='a', newline='') as file:
			writer = csv.writer(file)
			writer.writerow([model_name, dataset_name, f'{score} %'])

		joblib.dump(RFclassifier,f'models/{model_name}')
		open('models/features.pkl', 'wb').write(pickle.dumps(features))

		return None
	else:
		raise FileNotFoundError
